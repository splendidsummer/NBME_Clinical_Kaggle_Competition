{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>[NBME - Score Clinical Patient Notes](https://www.kaggle.com/c/nbme-score-clinical-patient-notes/overview)</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-24T08:51:51.709757Z",
     "iopub.status.busy": "2022-02-24T08:51:51.709213Z",
     "iopub.status.idle": "2022-02-24T08:51:51.737862Z",
     "shell.execute_reply": "2022-02-24T08:51:51.736902Z",
     "shell.execute_reply.started": "2022-02-24T08:51:51.709675Z"
    }
   },
   "outputs": [],
   "source": [
    "# The following is necessary if you want to use the fast tokenizer for deberta v2 or v3\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "transformers_path = Path(\"/usr/local/lib/python3.7/dist-packages/transformers\")\n",
    "\n",
    "input_dir = Path(\"/home/others/nbme/\")\n",
    "\n",
    "convert_file = input_dir / \"convert_slow_tokenizer.py\"\n",
    "conversion_path = transformers_path/convert_file.name\n",
    "\n",
    "if conversion_path.exists():\n",
    "    conversion_path.unlink()\n",
    "\n",
    "shutil.copy(convert_file, transformers_path)\n",
    "deberta_v2_path = transformers_path / \"models\" / \"deberta_v2\"\n",
    "\n",
    "for filename in ['tokenization_deberta_v2.py', 'tokenization_deberta_v2_fast.py', \"deberta__init__.py\"]:\n",
    "    if str(filename).startswith(\"deberta\"):\n",
    "        filepath = deberta_v2_path/str(filename).replace(\"deberta\", \"\")\n",
    "    else:\n",
    "        filepath = deberta_v2_path/filename\n",
    "    if filepath.exists():\n",
    "        filepath.unlink()\n",
    "\n",
    "    shutil.copy(input_dir/filename, filepath)\n",
    "    \n",
    "import os\n",
    "\n",
    "OUTPUT_DIR = './'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-02-24T08:51:51.742489Z",
     "iopub.status.busy": "2022-02-24T08:51:51.739662Z",
     "iopub.status.idle": "2022-02-24T08:51:51.762363Z",
     "shell.execute_reply": "2022-02-24T08:51:51.761456Z",
     "shell.execute_reply.started": "2022-02-24T08:51:51.742446Z"
    },
    "papermill": {
     "duration": 12.101116,
     "end_time": "2022-01-25T03:36:01.375577",
     "exception": false,
     "start_time": "2022-01-25T03:35:49.274461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import spacy\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "import ast\n",
    "import sys\n",
    "import copy\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import string\n",
    "import pickle\n",
    "import random\n",
    "import joblib\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# os.system('pip uninstall -y transformers')\n",
    "# os.system('python -m pip install --no-index --find-links=../input/nbme-pip-wheels transformers')\n",
    "import tokenizers\n",
    "import transformers\n",
    "print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
    "print(f\"transformers.__version__: {transformers.__version__}\")\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**数据解析**\n",
    "\n",
    "本次比赛提供了5份数据分别是 train, test, features, patient_notes, submission， 其中test, submission为提交答案时用\n",
    "\n",
    "重点是如下3个文件\n",
    "\n",
    "train 文件标记了每个病例中，不同症状的相关描述\n",
    "\n",
    "features 中给出了所有病症的名称和id\n",
    "\n",
    "patient_notes 中给出了每份病例的详细描述\n",
    "\n",
    "总体来说我们希望，通过对病例和症状的分析和挖掘，自动的找出不同病症在病例中的相关描述"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-02-24T08:51:51.766487Z",
     "iopub.status.busy": "2022-02-24T08:51:51.765206Z",
     "iopub.status.idle": "2022-02-24T08:51:52.149747Z",
     "shell.execute_reply": "2022-02-24T08:51:52.148961Z",
     "shell.execute_reply.started": "2022-02-24T08:51:51.766442Z"
    },
    "papermill": {
     "duration": 2.983333,
     "end_time": "2022-01-25T03:36:04.384698",
     "exception": false,
     "start_time": "2022-01-25T03:36:01.401365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "features = pd.read_csv(\"features.csv\")\n",
    "patient_notes = pd.read_csv(\"patient_notes.csv\")\n",
    "submission = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02516,
     "end_time": "2022-01-25T03:36:04.435908",
     "exception": false,
     "start_time": "2022-01-25T03:36:04.410748",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3.1\"></a>\n",
    "## Train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**训练数据Columns解析:**\n",
    "* `id` - 一个unique 标记符来表示 patient note number - feature number 对.\n",
    "* `pn_num` - patient note number 可以当成病例号.\n",
    "* `feature_num` - feature number 可以看作不同病症的一个id.\n",
    "* `case_num` - 病例所属的case id 之后会用来关联起病人patient note的文本描述和对应症状的文本描述.\n",
    "* `annotation` - patient note中体现相关症状的描述， 一个病例中可能对同一个疾病症状存在多处描述.\n",
    "* `location` - annotation所在的病例中的char 级别的位置."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-02-24T08:51:52.152398Z",
     "iopub.status.busy": "2022-02-24T08:51:52.151997Z",
     "iopub.status.idle": "2022-02-24T08:51:52.181565Z",
     "shell.execute_reply": "2022-02-24T08:51:52.180832Z",
     "shell.execute_reply.started": "2022-02-24T08:51:52.152356Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'\\033[92mNumber of rows in train data: {train.shape[0]}')\n",
    "print(f'\\033[94mNumber of columns in train data: {train.shape[1]}')\n",
    "print(f'\\033[91mNumber of values in train data: {train.count().sum()}')\n",
    "print(f'\\033[91mNumber missing values in train data: {sum(train.isna().sum())}')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data\n",
    "<a id=\"3.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-02-24T08:51:52.183480Z",
     "iopub.status.busy": "2022-02-24T08:51:52.182986Z",
     "iopub.status.idle": "2022-02-24T08:51:52.198560Z",
     "shell.execute_reply": "2022-02-24T08:51:52.197753Z",
     "shell.execute_reply.started": "2022-02-24T08:51:52.183442Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'\\033[92mNumber of rows in test data: {test.shape[0]}')\n",
    "print(f'\\033[94mNumber of columns in test data: {test.shape[1]}')\n",
    "print(f'\\033[91mNumber of values in train data: {test.count().sum()}')\n",
    "print(f'\\033[91mNo of rows with missing values  in test data: {sum(test.isna().sum())}')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patient Notes Data\n",
    "<a id=\"3.3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Column Description :**\n",
    "* `pn_num` - patient note 病例id.\n",
    "* `case_num` - case num 用来关联起病人patient note的文本描述和对应症状的文本描述.\n",
    "* `pn_history` - patient note的文本描述"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick view of Patient Notes Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-02-24T08:51:52.200386Z",
     "iopub.status.busy": "2022-02-24T08:51:52.199907Z",
     "iopub.status.idle": "2022-02-24T08:51:52.219727Z",
     "shell.execute_reply": "2022-02-24T08:51:52.218933Z",
     "shell.execute_reply.started": "2022-02-24T08:51:52.200334Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'\\033[92mNumber of rows in test data: {patient_notes.shape[0]}')\n",
    "print(f'\\033[94mNumber of columns in test data: {patient_notes.shape[1]}')\n",
    "print(f'\\033[91mNumber of values in train data: {patient_notes.count().sum()}')\n",
    "patient_notes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Patient Note "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-02-24T08:51:52.221488Z",
     "iopub.status.busy": "2022-02-24T08:51:52.221046Z",
     "iopub.status.idle": "2022-02-24T08:51:52.226730Z",
     "shell.execute_reply": "2022-02-24T08:51:52.225872Z",
     "shell.execute_reply.started": "2022-02-24T08:51:52.221449Z"
    }
   },
   "outputs": [],
   "source": [
    "print(patient_notes[\"pn_history\"].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patient Notes Distribution ( Per case ) \n",
    "<a id=\"3.3.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-02-24T08:51:52.228650Z",
     "iopub.status.busy": "2022-02-24T08:51:52.228089Z",
     "iopub.status.idle": "2022-02-24T08:51:52.356421Z",
     "shell.execute_reply": "2022-02-24T08:51:52.355659Z",
     "shell.execute_reply.started": "2022-02-24T08:51:52.228611Z"
    }
   },
   "outputs": [],
   "source": [
    "notes_counts = patient_notes.groupby(\"case_num\").count()\n",
    "fig = px.bar(data_frame =notes_counts, \n",
    "             x = notes_counts.index,\n",
    "             y = 'pn_num' , \n",
    "             color = \"pn_num\",\n",
    "             color_continuous_scale=\"Emrld\") \n",
    "fig.update_layout(title = {\n",
    "        'text': 'Distribution of patient notes for each case',\n",
    "        'y':0.95,\n",
    "        'x':0.48,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'} ,\n",
    "                   xaxis = dict(\n",
    "        tickmode = 'array',\n",
    "        tickvals = [0, 1,2, 3, 4,5, 6,7,8,9],\n",
    "        ticktext = ['Case 0', 'Case 1', 'Case 2', 'Case 3', 'Case 4', 'Case 5', 'Case 6', 'Case 7', 'Case 8', 'Case 9']),\n",
    "                  template = \"plotly_white\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-24T08:51:52.358634Z",
     "iopub.status.busy": "2022-02-24T08:51:52.357689Z",
     "iopub.status.idle": "2022-02-24T08:51:52.372055Z",
     "shell.execute_reply": "2022-02-24T08:51:52.371215Z",
     "shell.execute_reply.started": "2022-02-24T08:51:52.358593Z"
    }
   },
   "outputs": [],
   "source": [
    "features[features['case_num']==3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patient Notes Length Distribution \n",
    "<a id=\"3.3.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-02-24T08:51:52.376106Z",
     "iopub.status.busy": "2022-02-24T08:51:52.375903Z",
     "iopub.status.idle": "2022-02-24T08:51:52.638460Z",
     "shell.execute_reply": "2022-02-24T08:51:52.637677Z",
     "shell.execute_reply.started": "2022-02-24T08:51:52.376080Z"
    }
   },
   "outputs": [],
   "source": [
    "all_notes = []\n",
    "all_notes_len = []\n",
    "for notes in patient_notes['pn_history']:\n",
    "    all_notes.append(notes)\n",
    "    all_notes_len.append(len(notes))\n",
    "print(\"Average length of Patient History - \",np.mean(all_notes_len))\n",
    "fig = px.histogram(x = all_notes_len,nbins = 100)\n",
    "fig.update_xaxes(title = \"Lenght of patient Notes\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-02T03:39:40.557972Z",
     "iopub.status.busy": "2022-02-02T03:39:40.55767Z",
     "iopub.status.idle": "2022-02-02T03:39:40.562211Z",
     "shell.execute_reply": "2022-02-02T03:39:40.561274Z",
     "shell.execute_reply.started": "2022-02-02T03:39:40.557943Z"
    }
   },
   "source": [
    "## Features Data\n",
    "<a id=\"3.4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Column Description :**\n",
    "* `feature_num` - feature number 可以看作不同病症的一个id.\n",
    "* `case_num` - 病例所属的case id 之后会用来关联起病人patient note的文本描述和对应症状的文本描述.\n",
    "* `feature_text` - 疾病文本描述"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick view of features Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-02-24T08:51:52.640247Z",
     "iopub.status.busy": "2022-02-24T08:51:52.639812Z",
     "iopub.status.idle": "2022-02-24T08:51:52.657175Z",
     "shell.execute_reply": "2022-02-24T08:51:52.656392Z",
     "shell.execute_reply.started": "2022-02-24T08:51:52.640212Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'\\033[92mNumber of rows in test data: {features.shape[0]}')\n",
    "print(f'\\033[94mNumber of columns in test data: {features.shape[1]}')\n",
    "print(f'\\033[91mNumber of values in train data: {features.count().sum()}')\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Feature text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-02-24T08:51:52.659240Z",
     "iopub.status.busy": "2022-02-24T08:51:52.658462Z",
     "iopub.status.idle": "2022-02-24T08:51:52.664858Z",
     "shell.execute_reply": "2022-02-24T08:51:52.664126Z",
     "shell.execute_reply.started": "2022-02-24T08:51:52.659201Z"
    }
   },
   "outputs": [],
   "source": [
    "features[\"feature_text\"].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Distribution (per Case) \n",
    "<a id=\"3.4.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-02-24T08:51:52.667026Z",
     "iopub.status.busy": "2022-02-24T08:51:52.666075Z",
     "iopub.status.idle": "2022-02-24T08:51:52.757974Z",
     "shell.execute_reply": "2022-02-24T08:51:52.757265Z",
     "shell.execute_reply.started": "2022-02-24T08:51:52.666878Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_counts = features.groupby(\"case_num\").count()\n",
    "fig = px.bar(data_frame =feature_counts, \n",
    "             x = feature_counts.index,\n",
    "             y = 'feature_num' , \n",
    "             color = \"feature_num\",\n",
    "             color_continuous_scale=\"Emrld\") \n",
    "fig.update_layout(title = {\n",
    "        'text': 'Distribution of Features for each case',\n",
    "        'y':0.95,\n",
    "        'x':0.48,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'} ,\n",
    "                   xaxis = dict(\n",
    "        tickmode = 'array',\n",
    "        tickvals = [0, 1,2, 3, 4,5, 6,7,8,9],\n",
    "        ticktext = ['Case 0', 'Case 1', 'Case 2', 'Case 3', 'Case 4', 'Case 5', 'Case 6', 'Case 7', 'Case 8', 'Case 9']),\n",
    "                  template = \"plotly_white\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Length Distribution \n",
    "<a id=\"3.4.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-02-24T08:51:52.759527Z",
     "iopub.status.busy": "2022-02-24T08:51:52.759201Z",
     "iopub.status.idle": "2022-02-24T08:51:52.838394Z",
     "shell.execute_reply": "2022-02-24T08:51:52.837597Z",
     "shell.execute_reply.started": "2022-02-24T08:51:52.759490Z"
    }
   },
   "outputs": [],
   "source": [
    "all_feat = []\n",
    "all_feat_len = []\n",
    "for notes in features['feature_text']:\n",
    "    all_feat.append(notes)\n",
    "    all_feat_len.append(len(notes))\n",
    "print(\"Average length of Features - \",np.mean(all_feat_len))\n",
    "fig = px.histogram(x = all_feat_len,nbins = 200)\n",
    "fig.update_layout(template=\"plotly_white\")\n",
    "fig.update_xaxes(title = \"Lenght of Features\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empty Annotation count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-02-24T08:51:52.840070Z",
     "iopub.status.busy": "2022-02-24T08:51:52.839818Z",
     "iopub.status.idle": "2022-02-24T08:51:52.849422Z",
     "shell.execute_reply": "2022-02-24T08:51:52.848545Z",
     "shell.execute_reply.started": "2022-02-24T08:51:52.840036Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Number of Empty annotions and locations = \", sum(train[\"location\"] == '[]'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotation Count Distribution\n",
    "<a id=\"3.6.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-02-24T08:51:52.851283Z",
     "iopub.status.busy": "2022-02-24T08:51:52.851010Z",
     "iopub.status.idle": "2022-02-24T08:51:56.629124Z",
     "shell.execute_reply": "2022-02-24T08:51:56.628397Z",
     "shell.execute_reply.started": "2022-02-24T08:51:52.851243Z"
    }
   },
   "outputs": [],
   "source": [
    "train[\"location\"] = train[\"location\"].apply(eval)\n",
    "train['annotation'] = train['annotation'].apply(eval)\n",
    "train[\"annot_count\"] = 0\n",
    "for i in range(len(train)):\n",
    "    train[\"annot_count\"][i] = len(train[\"annotation\"][i])\n",
    "total_annot = 0\n",
    "for idx in train[\"annot_count\"].value_counts().sort_index().index:\n",
    "    total_annot += train[\"annot_count\"].value_counts().sort_index()[idx] * idx\n",
    "print(f'\\033[92mTotal number of Annotations is train data  : ' , total_annot)\n",
    "print(f'\\033[94mAnnotation count per row: ')\n",
    "print(f'\\033[94m',train[\"annot_count\"].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-02-24T08:51:56.631907Z",
     "iopub.status.busy": "2022-02-24T08:51:56.631396Z",
     "iopub.status.idle": "2022-02-24T08:51:56.717912Z",
     "shell.execute_reply": "2022-02-24T08:51:56.717208Z",
     "shell.execute_reply.started": "2022-02-24T08:51:56.631856Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = px.bar(data_frame =train, \n",
    "             x = train[\"annot_count\"].value_counts().sort_index().index,\n",
    "             y = train[\"annot_count\"].value_counts().sort_index() , \n",
    "             color = train[\"annot_count\"].value_counts().sort_index(),\n",
    "             color_continuous_scale=\"Emrld\") \n",
    "fig.update_xaxes(title =\"Number of Annotations\")\n",
    "fig.update_yaxes(title =\"Number of Rows\")\n",
    "fig.update_layout(title = {\n",
    "        'text': 'Number of Annotations per row',\n",
    "        'y':0.95,\n",
    "        'x':0.48,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'} ,\n",
    "                   \n",
    "                  template = \"plotly_white\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotation Length Distribution \n",
    "<a id=\"3.6.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-02-24T08:51:56.719826Z",
     "iopub.status.busy": "2022-02-24T08:51:56.719369Z",
     "iopub.status.idle": "2022-02-24T08:51:56.847554Z",
     "shell.execute_reply": "2022-02-24T08:51:56.846887Z",
     "shell.execute_reply.started": "2022-02-24T08:51:56.719790Z"
    }
   },
   "outputs": [],
   "source": [
    "annot_lengths = []\n",
    "all_annot_words = []\n",
    "for annot in train[\"annotation\"]:\n",
    "    for words in annot:\n",
    "        annot_lengths.append(len(words))\n",
    "        all_annot_words.append(words)\n",
    "print(\"Average length of Annotations - \",np.mean(annot_lengths))\n",
    "fig = px.histogram(x = annot_lengths,nbins = 300)\n",
    "fig.update_layout(template=\"plotly_white\")\n",
    "fig.update_xaxes(title = \"Lenght of Annotation\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-24T08:51:56.849263Z",
     "iopub.status.busy": "2022-02-24T08:51:56.848711Z",
     "iopub.status.idle": "2022-02-24T08:51:56.857363Z",
     "shell.execute_reply": "2022-02-24T08:51:56.856414Z",
     "shell.execute_reply.started": "2022-02-24T08:51:56.849225Z"
    }
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# CFG\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    debug=False\n",
    "    apex=False\n",
    "    print_freq=100\n",
    "    num_workers=4\n",
    "    model=\"microsoft/deberta-v3-large\"\n",
    "    scheduler='cosine' # ['linear', 'cosine']\n",
    "    batch_scheduler=True\n",
    "    num_cycles=0.5\n",
    "    num_warmup_steps=0.1\n",
    "    epochs=2\n",
    "    encoder_lr=2e-5\n",
    "    decoder_lr=2e-5\n",
    "    min_lr=1e-6\n",
    "    eps=1e-6\n",
    "    betas=(0.9, 0.999)\n",
    "    batch_size=8\n",
    "    fc_dropout=0.2\n",
    "    max_len=512\n",
    "    weight_decay=0.01\n",
    "    gradient_accumulation_steps=1\n",
    "    max_grad_norm=500\n",
    "    seed=42\n",
    "    n_fold=5\n",
    "    trn_fold=[4]\n",
    "    train=True\n",
    "    \n",
    "if CFG.debug:\n",
    "    CFG.epochs = 5\n",
    "    CFG.trn_fold = [0,1,2,3,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-24T08:51:56.859319Z",
     "iopub.status.busy": "2022-02-24T08:51:56.858996Z",
     "iopub.status.idle": "2022-02-24T08:51:56.869966Z",
     "shell.execute_reply": "2022-02-24T08:51:56.869233Z",
     "shell.execute_reply.started": "2022-02-24T08:51:56.859283Z"
    }
   },
   "outputs": [],
   "source": [
    "# From https://www.kaggle.com/theoviel/evaluation-metric-folds-baseline\n",
    "\n",
    "def micro_f1(preds, truths):\n",
    "    \"\"\"\n",
    "    Micro f1 on binary arrays.\n",
    "\n",
    "    Args:\n",
    "        preds (list of lists of ints): Predictions.\n",
    "        truths (list of lists of ints): Ground truths.\n",
    "\n",
    "    Returns:\n",
    "        float: f1 score.\n",
    "    \"\"\"\n",
    "    # Micro : aggregating over all instances\n",
    "    preds = np.concatenate(preds)\n",
    "    truths = np.concatenate(truths)\n",
    "    return f1_score(truths, preds)\n",
    "\n",
    "\n",
    "def spans_to_binary(spans, length=None):\n",
    "    \"\"\"\n",
    "    Converts spans to a binary array indicating whether each character is in the span.\n",
    "\n",
    "    Args:\n",
    "        spans (list of lists of two ints): Spans.\n",
    "\n",
    "    Returns:\n",
    "        np array [length]: Binarized spans.\n",
    "    \"\"\"\n",
    "    length = np.max(spans) if length is None else length\n",
    "    binary = np.zeros(length)\n",
    "    for start, end in spans:\n",
    "        binary[start:end] = 1\n",
    "    return binary\n",
    "\n",
    "\n",
    "def span_micro_f1(preds, truths):\n",
    "    \"\"\"\n",
    "    Micro f1 on spans.\n",
    "\n",
    "    Args:\n",
    "        preds (list of lists of two ints): Prediction spans.\n",
    "        truths (list of lists of two ints): Ground truth spans.\n",
    "\n",
    "    Returns:\n",
    "        float: f1 score.\n",
    "    \"\"\"\n",
    "    bin_preds = []\n",
    "    bin_truths = []\n",
    "    for pred, truth in zip(preds, truths):\n",
    "        if not len(pred) and not len(truth):\n",
    "            continue\n",
    "        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n",
    "        bin_preds.append(spans_to_binary(pred, length))\n",
    "        bin_truths.append(spans_to_binary(truth, length))\n",
    "    return micro_f1(bin_preds, bin_truths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-24T08:51:56.871826Z",
     "iopub.status.busy": "2022-02-24T08:51:56.871549Z",
     "iopub.status.idle": "2022-02-24T08:51:56.893483Z",
     "shell.execute_reply": "2022-02-24T08:51:56.892680Z",
     "shell.execute_reply.started": "2022-02-24T08:51:56.871789Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_labels_for_scoring(df):\n",
    "    # example: ['0 1', '3 4'] -> ['0 1; 3 4']\n",
    "    df['location_for_create_labels'] = [ast.literal_eval(f'[]')] * len(df)\n",
    "    for i in range(len(df)):\n",
    "        lst = df.loc[i, 'location']\n",
    "        if lst:\n",
    "            new_lst = ';'.join(lst)\n",
    "            df.loc[i, 'location_for_create_labels'] = ast.literal_eval(f'[[\"{new_lst}\"]]')\n",
    "    # create labels\n",
    "    truths = []\n",
    "    for location_list in df['location_for_create_labels'].values:\n",
    "        truth = []\n",
    "        if len(location_list) > 0:\n",
    "            location = location_list[0]\n",
    "            for loc in [s.split() for s in location.split(';')]:\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                truth.append([start, end])\n",
    "        truths.append(truth)\n",
    "    return truths\n",
    "\n",
    "\n",
    "def get_char_probs(texts, predictions, tokenizer):\n",
    "    results = [np.zeros(len(t)) for t in texts]\n",
    "    for i, (text, prediction) in enumerate(zip(texts, predictions)):\n",
    "        encoded = tokenizer(text, \n",
    "                            add_special_tokens=True,\n",
    "                            return_offsets_mapping=True)\n",
    "        for idx, (offset_mapping, pred) in enumerate(zip(encoded['offset_mapping'], prediction)):\n",
    "            start = offset_mapping[0]\n",
    "            end = offset_mapping[1]\n",
    "            results[i][start:end] = pred\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_results(char_probs, th=0.5):\n",
    "    results = []\n",
    "    for char_prob in char_probs:\n",
    "        result = np.where(char_prob >= th)[0] + 1\n",
    "        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n",
    "        result = [f\"{min(r)} {max(r)}\" for r in result]\n",
    "        result = \";\".join(result)\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_predictions(results):\n",
    "    predictions = []\n",
    "    for result in results:\n",
    "        prediction = []\n",
    "        if result != \"\":\n",
    "            for loc in [s.split() for s in result.split(';')]:\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                prediction.append([start, end])\n",
    "        predictions.append(prediction)\n",
    "    return predictions\n",
    "\n",
    "# ====================================================\n",
    "# Utils\n",
    "# ====================================================\n",
    "def get_score(y_true, y_pred):\n",
    "    score = span_micro_f1(y_true, y_pred)\n",
    "    return score\n",
    "\n",
    "\n",
    "def get_logger(filename=OUTPUT_DIR+'train'):\n",
    "    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=f\"{filename}.log\")\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = get_logger()\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2022-02-24T08:51:56.895508Z",
     "iopub.status.busy": "2022-02-24T08:51:56.894882Z",
     "iopub.status.idle": "2022-02-24T08:51:57.452322Z",
     "shell.execute_reply": "2022-02-24T08:51:57.451498Z",
     "shell.execute_reply.started": "2022-02-24T08:51:56.895469Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Data Loading\n",
    "# ====================================================\n",
    "train = pd.read_csv('train.csv')\n",
    "train['annotation'] = train['annotation'].apply(ast.literal_eval)\n",
    "train['location'] = train['location'].apply(ast.literal_eval)\n",
    "features = pd.read_csv('features.csv')\n",
    "def preprocess_features(features):\n",
    "    features.loc[27, 'feature_text'] = \"Last-Pap-smear-1-year-ago\"\n",
    "    return features\n",
    "features = preprocess_features(features)\n",
    "patient_notes = pd.read_csv('patient_notes.csv')\n",
    "\n",
    "print(f\"train.shape: {train.shape}\")\n",
    "display(train.head())\n",
    "print(f\"features.shape: {features.shape}\")\n",
    "display(features.head())\n",
    "print(f\"patient_notes.shape: {patient_notes.shape}\")\n",
    "display(patient_notes.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge train data with patient note and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-24T08:51:57.454067Z",
     "iopub.status.busy": "2022-02-24T08:51:57.453798Z",
     "iopub.status.idle": "2022-02-24T08:51:57.488141Z",
     "shell.execute_reply": "2022-02-24T08:51:57.487403Z",
     "shell.execute_reply.started": "2022-02-24T08:51:57.454028Z"
    }
   },
   "outputs": [],
   "source": [
    "train = train.merge(features, on=['feature_num', 'case_num'], how='left')\n",
    "train = train.merge(patient_notes, on=['pn_num', 'case_num'], how='left')\n",
    "display(train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Manually correct some annotation errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "execution": {
     "iopub.execute_input": "2022-02-24T08:51:57.490362Z",
     "iopub.status.busy": "2022-02-24T08:51:57.489858Z",
     "iopub.status.idle": "2022-02-24T08:51:57.588796Z",
     "shell.execute_reply": "2022-02-24T08:51:57.587841Z",
     "shell.execute_reply.started": "2022-02-24T08:51:57.490310Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# incorrect annotation\n",
    "train.loc[338, 'annotation'] = ast.literal_eval('[[\"father heart attack\"]]')\n",
    "train.loc[338, 'location'] = ast.literal_eval('[[\"764 783\"]]')\n",
    "\n",
    "train.loc[621, 'annotation'] = ast.literal_eval('[[\"for the last 2-3 months\"]]')\n",
    "train.loc[621, 'location'] = ast.literal_eval('[[\"77 100\"]]')\n",
    "\n",
    "train.loc[655, 'annotation'] = ast.literal_eval('[[\"no heat intolerance\"], [\"no cold intolerance\"]]')\n",
    "train.loc[655, 'location'] = ast.literal_eval('[[\"285 292;301 312\"], [\"285 287;296 312\"]]')\n",
    "\n",
    "train.loc[1262, 'annotation'] = ast.literal_eval('[[\"mother thyroid problem\"]]')\n",
    "train.loc[1262, 'location'] = ast.literal_eval('[[\"551 557;565 580\"]]')\n",
    "\n",
    "train.loc[1265, 'annotation'] = ast.literal_eval('[[\\'felt like he was going to \"pass out\"\\']]')\n",
    "train.loc[1265, 'location'] = ast.literal_eval('[[\"131 135;181 212\"]]')\n",
    "\n",
    "train.loc[1396, 'annotation'] = ast.literal_eval('[[\"stool , with no blood\"]]')\n",
    "train.loc[1396, 'location'] = ast.literal_eval('[[\"259 280\"]]')\n",
    "\n",
    "train.loc[1591, 'annotation'] = ast.literal_eval('[[\"diarrhoe non blooody\"]]')\n",
    "train.loc[1591, 'location'] = ast.literal_eval('[[\"176 184;201 212\"]]')\n",
    "\n",
    "train.loc[1615, 'annotation'] = ast.literal_eval('[[\"diarrhea for last 2-3 days\"]]')\n",
    "train.loc[1615, 'location'] = ast.literal_eval('[[\"249 257;271 288\"]]')\n",
    "\n",
    "train.loc[1664, 'annotation'] = ast.literal_eval('[[\"no vaginal discharge\"]]')\n",
    "train.loc[1664, 'location'] = ast.literal_eval('[[\"822 824;907 924\"]]')\n",
    "\n",
    "train.loc[1714, 'annotation'] = ast.literal_eval('[[\"started about 8-10 hours ago\"]]')\n",
    "train.loc[1714, 'location'] = ast.literal_eval('[[\"101 129\"]]')\n",
    "\n",
    "train.loc[1929, 'annotation'] = ast.literal_eval('[[\"no blood in the stool\"]]')\n",
    "train.loc[1929, 'location'] = ast.literal_eval('[[\"531 539;549 561\"]]')\n",
    "\n",
    "train.loc[2134, 'annotation'] = ast.literal_eval('[[\"last sexually active 9 months ago\"]]')\n",
    "train.loc[2134, 'location'] = ast.literal_eval('[[\"540 560;581 593\"]]')\n",
    "\n",
    "train.loc[2191, 'annotation'] = ast.literal_eval('[[\"right lower quadrant pain\"]]')\n",
    "train.loc[2191, 'location'] = ast.literal_eval('[[\"32 57\"]]')\n",
    "\n",
    "train.loc[2553, 'annotation'] = ast.literal_eval('[[\"diarrhoea no blood\"]]')\n",
    "train.loc[2553, 'location'] = ast.literal_eval('[[\"308 317;376 384\"]]')\n",
    "\n",
    "train.loc[3124, 'annotation'] = ast.literal_eval('[[\"sweating\"]]')\n",
    "train.loc[3124, 'location'] = ast.literal_eval('[[\"549 557\"]]')\n",
    "\n",
    "train.loc[3858, 'annotation'] = ast.literal_eval('[[\"previously as regular\"], [\"previously eveyr 28-29 days\"], [\"previously lasting 5 days\"], [\"previously regular flow\"]]')\n",
    "train.loc[3858, 'location'] = ast.literal_eval('[[\"102 123\"], [\"102 112;125 141\"], [\"102 112;143 157\"], [\"102 112;159 171\"]]')\n",
    "\n",
    "train.loc[4373, 'annotation'] = ast.literal_eval('[[\"for 2 months\"]]')\n",
    "train.loc[4373, 'location'] = ast.literal_eval('[[\"33 45\"]]')\n",
    "\n",
    "train.loc[4763, 'annotation'] = ast.literal_eval('[[\"35 year old\"]]')\n",
    "train.loc[4763, 'location'] = ast.literal_eval('[[\"5 16\"]]')\n",
    "\n",
    "train.loc[4782, 'annotation'] = ast.literal_eval('[[\"darker brown stools\"]]')\n",
    "train.loc[4782, 'location'] = ast.literal_eval('[[\"175 194\"]]')\n",
    "\n",
    "train.loc[4908, 'annotation'] = ast.literal_eval('[[\"uncle with peptic ulcer\"]]')\n",
    "train.loc[4908, 'location'] = ast.literal_eval('[[\"700 723\"]]')\n",
    "\n",
    "train.loc[6016, 'annotation'] = ast.literal_eval('[[\"difficulty falling asleep\"]]')\n",
    "train.loc[6016, 'location'] = ast.literal_eval('[[\"225 250\"]]')\n",
    "\n",
    "train.loc[6192, 'annotation'] = ast.literal_eval('[[\"helps to take care of aging mother and in-laws\"]]')\n",
    "train.loc[6192, 'location'] = ast.literal_eval('[[\"197 218;236 260\"]]')\n",
    "\n",
    "train.loc[6380, 'annotation'] = ast.literal_eval('[[\"No hair changes\"], [\"No skin changes\"], [\"No GI changes\"], [\"No palpitations\"], [\"No excessive sweating\"]]')\n",
    "train.loc[6380, 'location'] = ast.literal_eval('[[\"480 482;507 519\"], [\"480 482;499 503;512 519\"], [\"480 482;521 531\"], [\"480 482;533 545\"], [\"480 482;564 582\"]]')\n",
    "\n",
    "train.loc[6562, 'annotation'] = ast.literal_eval('[[\"stressed due to taking care of her mother\"], [\"stressed due to taking care of husbands parents\"]]')\n",
    "train.loc[6562, 'location'] = ast.literal_eval('[[\"290 320;327 337\"], [\"290 320;342 358\"]]')\n",
    "\n",
    "train.loc[6862, 'annotation'] = ast.literal_eval('[[\"stressor taking care of many sick family members\"]]')\n",
    "train.loc[6862, 'location'] = ast.literal_eval('[[\"288 296;324 363\"]]')\n",
    "\n",
    "train.loc[7022, 'annotation'] = ast.literal_eval('[[\"heart started racing and felt numbness for the 1st time in her finger tips\"]]')\n",
    "train.loc[7022, 'location'] = ast.literal_eval('[[\"108 182\"]]')\n",
    "\n",
    "train.loc[7422, 'annotation'] = ast.literal_eval('[[\"first started 5 yrs\"]]')\n",
    "train.loc[7422, 'location'] = ast.literal_eval('[[\"102 121\"]]')\n",
    "\n",
    "train.loc[8876, 'annotation'] = ast.literal_eval('[[\"No shortness of breath\"]]')\n",
    "train.loc[8876, 'location'] = ast.literal_eval('[[\"481 483;533 552\"]]')\n",
    "\n",
    "train.loc[9027, 'annotation'] = ast.literal_eval('[[\"recent URI\"], [\"nasal stuffines, rhinorrhea, for 3-4 days\"]]')\n",
    "train.loc[9027, 'location'] = ast.literal_eval('[[\"92 102\"], [\"123 164\"]]')\n",
    "\n",
    "train.loc[9938, 'annotation'] = ast.literal_eval('[[\"irregularity with her cycles\"], [\"heavier bleeding\"], [\"changes her pad every couple hours\"]]')\n",
    "train.loc[9938, 'location'] = ast.literal_eval('[[\"89 117\"], [\"122 138\"], [\"368 402\"]]')\n",
    "\n",
    "train.loc[9973, 'annotation'] = ast.literal_eval('[[\"gaining 10-15 lbs\"]]')\n",
    "train.loc[9973, 'location'] = ast.literal_eval('[[\"344 361\"]]')\n",
    "\n",
    "train.loc[10513, 'annotation'] = ast.literal_eval('[[\"weight gain\"], [\"gain of 10-16lbs\"]]')\n",
    "train.loc[10513, 'location'] = ast.literal_eval('[[\"600 611\"], [\"607 623\"]]')\n",
    "\n",
    "train.loc[11551, 'annotation'] = ast.literal_eval('[[\"seeing her son knows are not real\"]]')\n",
    "train.loc[11551, 'location'] = ast.literal_eval('[[\"386 400;443 461\"]]')\n",
    "\n",
    "train.loc[11677, 'annotation'] = ast.literal_eval('[[\"saw him once in the kitchen after he died\"]]')\n",
    "train.loc[11677, 'location'] = ast.literal_eval('[[\"160 201\"]]')\n",
    "\n",
    "train.loc[12124, 'annotation'] = ast.literal_eval('[[\"tried Ambien but it didnt work\"]]')\n",
    "train.loc[12124, 'location'] = ast.literal_eval('[[\"325 337;349 366\"]]')\n",
    "\n",
    "train.loc[12279, 'annotation'] = ast.literal_eval('[[\"heard what she described as a party later than evening these things did not actually happen\"]]')\n",
    "train.loc[12279, 'location'] = ast.literal_eval('[[\"405 459;488 524\"]]')\n",
    "\n",
    "train.loc[12289, 'annotation'] = ast.literal_eval('[[\"experienced seeing her son at the kitchen table these things did not actually happen\"]]')\n",
    "train.loc[12289, 'location'] = ast.literal_eval('[[\"353 400;488 524\"]]')\n",
    "\n",
    "train.loc[13238, 'annotation'] = ast.literal_eval('[[\"SCRACHY THROAT\"], [\"RUNNY NOSE\"]]')\n",
    "train.loc[13238, 'location'] = ast.literal_eval('[[\"293 307\"], [\"321 331\"]]')\n",
    "\n",
    "train.loc[13297, 'annotation'] = ast.literal_eval('[[\"without improvement when taking tylenol\"], [\"without improvement when taking ibuprofen\"]]')\n",
    "train.loc[13297, 'location'] = ast.literal_eval('[[\"182 221\"], [\"182 213;225 234\"]]')\n",
    "\n",
    "train.loc[13299, 'annotation'] = ast.literal_eval('[[\"yesterday\"], [\"yesterday\"]]')\n",
    "train.loc[13299, 'location'] = ast.literal_eval('[[\"79 88\"], [\"409 418\"]]')\n",
    "\n",
    "train.loc[13845, 'annotation'] = ast.literal_eval('[[\"headache global\"], [\"headache throughout her head\"]]')\n",
    "train.loc[13845, 'location'] = ast.literal_eval('[[\"86 94;230 236\"], [\"86 94;237 256\"]]')\n",
    "\n",
    "train.loc[14083, 'annotation'] = ast.literal_eval('[[\"headache generalized in her head\"]]')\n",
    "train.loc[14083, 'location'] = ast.literal_eval('[[\"56 64;156 179\"]]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-24T08:51:57.590879Z",
     "iopub.status.busy": "2022-02-24T08:51:57.590358Z",
     "iopub.status.idle": "2022-02-24T08:51:57.612782Z",
     "shell.execute_reply": "2022-02-24T08:51:57.611945Z",
     "shell.execute_reply.started": "2022-02-24T08:51:57.590840Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train['annotation_length'] = train['annotation'].apply(len)\n",
    "display(train['annotation_length'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-24T08:51:57.614659Z",
     "iopub.status.busy": "2022-02-24T08:51:57.614206Z",
     "iopub.status.idle": "2022-02-24T08:51:57.640179Z",
     "shell.execute_reply": "2022-02-24T08:51:57.639359Z",
     "shell.execute_reply.started": "2022-02-24T08:51:57.614597Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Fold = GroupKFold(n_splits=CFG.n_fold)\n",
    "groups = train['pn_num'].values\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(train, train['location'], groups)):\n",
    "    train.loc[val_index, 'fold'] = int(n)\n",
    "train['fold'] = train['fold'].astype(int)\n",
    "display(train.groupby('fold').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## DataSet and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     8
    ],
    "execution": {
     "iopub.execute_input": "2022-02-24T08:51:57.642035Z",
     "iopub.status.busy": "2022-02-24T08:51:57.641772Z",
     "iopub.status.idle": "2022-02-24T08:52:30.067283Z",
     "shell.execute_reply": "2022-02-24T08:52:30.066592Z",
     "shell.execute_reply.started": "2022-02-24T08:51:57.641999Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from transformers.models.deberta_v2 import DebertaV2TokenizerFast\n",
    "tokenizer = DebertaV2TokenizerFast.from_pretrained(CFG.model)\n",
    "#tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n",
    "CFG.tokenizer = tokenizer\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# Define max_len\n",
    "# ====================================================\n",
    "for text_col in ['pn_history']:\n",
    "    pn_history_lengths = []\n",
    "    tk0 = tqdm(patient_notes[text_col].fillna(\"\").values, total=len(patient_notes))\n",
    "    for text in tk0:\n",
    "        length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n",
    "        pn_history_lengths.append(length)\n",
    "    LOGGER.info(f'{text_col} max(lengths): {max(pn_history_lengths)}')\n",
    "\n",
    "for text_col in ['feature_text']:\n",
    "    features_lengths = []\n",
    "    tk0 = tqdm(features[text_col].fillna(\"\").values, total=len(features))\n",
    "    for text in tk0:\n",
    "        length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n",
    "        features_lengths.append(length)\n",
    "    LOGGER.info(f'{text_col} max(lengths): {max(features_lengths)}')\n",
    "\n",
    "CFG.max_len = max(pn_history_lengths) + max(features_lengths) + 3 # cls & sep & sep\n",
    "LOGGER.info(f\"max_len: {CFG.max_len}\")\n",
    "\n",
    "# ====================================================\n",
    "# Dataset\n",
    "# ====================================================\n",
    "def prepare_input(cfg, text, feature_text):\n",
    "    inputs = cfg.tokenizer(text, feature_text, \n",
    "                           add_special_tokens=True,\n",
    "                           max_length=CFG.max_len,\n",
    "                           padding=\"max_length\",\n",
    "                           return_offsets_mapping=False)\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype=torch.long)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def create_label(cfg, text, annotation_length, location_list):\n",
    "    encoded = cfg.tokenizer(text,\n",
    "                            add_special_tokens=True,\n",
    "                            max_length=CFG.max_len,\n",
    "                            padding=\"max_length\",\n",
    "                            return_offsets_mapping=True)\n",
    "    offset_mapping = encoded['offset_mapping']\n",
    "    ignore_idxes = np.where(np.array(encoded.sequence_ids()) != 0)[0]\n",
    "    label = np.zeros(len(offset_mapping))\n",
    "    label[ignore_idxes] = -1\n",
    "    if annotation_length != 0:\n",
    "        for location in location_list:\n",
    "            for loc in [s.split() for s in location.split(';')]:\n",
    "                start_idx = -1\n",
    "                end_idx = -1\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                for idx in range(len(offset_mapping)):\n",
    "                    if (start_idx == -1) & (start < offset_mapping[idx][0]):\n",
    "                        start_idx = idx - 1\n",
    "                    if (end_idx == -1) & (end <= offset_mapping[idx][1]):\n",
    "                        end_idx = idx + 1\n",
    "                if start_idx == -1:\n",
    "                    start_idx = end_idx\n",
    "                if (start_idx != -1) & (end_idx != -1):\n",
    "                    label[start_idx:end_idx] = 1\n",
    "    return torch.tensor(label, dtype=torch.float)\n",
    "\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.feature_texts = df['feature_text'].values\n",
    "        self.pn_historys = df['pn_history'].values\n",
    "        self.annotation_lengths = df['annotation_length'].values\n",
    "        self.locations = df['location'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.feature_texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_input(self.cfg, \n",
    "                               self.pn_historys[item], \n",
    "                               self.feature_texts[item])\n",
    "        label = create_label(self.cfg, \n",
    "                             self.pn_historys[item], \n",
    "                             self.annotation_lengths[item], \n",
    "                             self.locations[item])\n",
    "        return inputs, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2022-02-24T08:52:30.071499Z",
     "iopub.status.busy": "2022-02-24T08:52:30.071067Z",
     "iopub.status.idle": "2022-02-24T08:52:30.085510Z",
     "shell.execute_reply": "2022-02-24T08:52:30.084757Z",
     "shell.execute_reply.started": "2022-02-24T08:52:30.071459Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Model\n",
    "# ====================================================\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n",
    "        else:\n",
    "            self.model = AutoModel(self.config)\n",
    "        self.fc_dropout_0 = nn.Dropout(0.1)\n",
    "        self.fc_dropout_1 = nn.Dropout(cfg.fc_dropout)\n",
    "        self.fc_dropout_2 = nn.Dropout(0.3)\n",
    "        self.fc_dropout_3 = nn.Dropout(0.4)\n",
    "        self.fc_dropout_4 = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(self.config.hidden_size, 1)\n",
    "        self._init_weights(self.fc)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        \n",
    "    def feature(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_states = outputs[0]\n",
    "        return last_hidden_states\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        feature = self.feature(inputs)\n",
    "        #output_0 = self.fc(self.fc_dropout_0(feature))\n",
    "        output_1 = self.fc(self.fc_dropout_1(feature))\n",
    "        #output_2 = self.fc(self.fc_dropout_2(feature))\n",
    "        #output_3 = self.fc(self.fc_dropout_3(feature))\n",
    "        #output_4 = self.fc(self.fc_dropout_4(feature))\n",
    "        output = output_1 #(output_0 + output_1 + output_2 + output_3 + output_4) / 5\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class FGM():\n",
    "    \"\"\"\n",
    "    定义对抗训练方法FGM,对模型embedding参数进行扰动\n",
    "    \"\"\"\n",
    "    def __init__(self, model, epsilon=0.25,):\n",
    "        # BERT模型\n",
    "        self.model = model\n",
    "        # 求干扰时的系数值\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "        self.backup = {}\n",
    "\n",
    "    def attack(self, emb_name='word_embeddings'):\n",
    "        \"\"\"\n",
    "        得到对抗样本\n",
    "        :param emb_name:模型中embedding的参数名\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # 循环遍历模型所有参数\n",
    "        for name, param in self.model.named_parameters():\n",
    "            # 如果当前参数在计算中保留了对应的梯度信息，并且包含了模型中embedding的参数名\n",
    "            if param.requires_grad and emb_name in name:\n",
    "                # 把真实参数保存起来\n",
    "                self.backup[name] = param.data.clone()\n",
    "                # 对参数的梯度求范数\n",
    "                norm = torch.norm(param.grad)\n",
    "                # 如果范数不等于0并且norm中没有缺失值\n",
    "                if norm != 0 and not torch.isnan(norm):\n",
    "                    # 计算扰动，param.grad / norm=单位向量，起到了sgn(param.grad)一样的作用\n",
    "                    r_at = self.epsilon * param.grad / norm\n",
    "                    # 在原参数的基础上添加扰动\n",
    "                    param.data.add_(r_at)\n",
    "\n",
    "    def restore(self, emb_name='word_embeddings'):\n",
    "        \"\"\"\n",
    "        将模型原本的参数复原\n",
    "        :param emb_name:模型中embedding的参数名\n",
    "        \"\"\"\n",
    "        # 循环遍历模型所有参数\n",
    "        for name, param in self.model.named_parameters():\n",
    "            # 如果当前参数在计算中保留了对应的梯度信息，并且包含了模型中embedding的参数名\n",
    "            if param.requires_grad and emb_name in name:\n",
    "                # 断言\n",
    "                assert name in self.backup\n",
    "                # 取出模型真实参数\n",
    "                param.data = self.backup[name]\n",
    "        # 清空self.backup\n",
    "        self.backup = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2022-02-24T08:52:30.087449Z",
     "iopub.status.busy": "2022-02-24T08:52:30.086960Z",
     "iopub.status.idle": "2022-02-24T08:52:30.135924Z",
     "shell.execute_reply": "2022-02-24T08:52:30.135170Z",
     "shell.execute_reply.started": "2022-02-24T08:52:30.087411Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Helper functions\n",
    "# ====================================================\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    model.train()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n",
    "    losses = AverageMeter()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    for step, (inputs, labels) in enumerate(train_loader):\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        y_preds = model(inputs)\n",
    "        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n",
    "        loss = torch.masked_select(loss, labels.view(-1, 1) != -1).mean()\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        loss.backward()\n",
    "        #grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "            if CFG.batch_scheduler:\n",
    "                scheduler.step()\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'LR: {lr:.8f}  '\n",
    "                  .format(epoch+1, step, len(train_loader), \n",
    "                          remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                          loss=losses,\n",
    "                          lr=scheduler.get_lr()[0]))\n",
    "        \n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "\n",
    "def train_fn_adv(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    model.train()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n",
    "    losses = AverageMeter()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    fgm = FGM(model)\n",
    "    for step, (inputs, labels) in enumerate(train_loader):\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        y_preds = model(inputs)\n",
    "        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n",
    "        loss = torch.masked_select(loss, labels.view(-1, 1) != -1).mean()\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        loss.backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            fgm.attack() \n",
    "            # embedding参数被修改，此时，输入序列得到的embedding表征不一样                     \n",
    "            y_preds_adv = model(inputs)\n",
    "            loss_adv = criterion(y_preds_adv.view(-1, 1), labels.view(-1, 1))\n",
    "            loss_adv = torch.masked_select(loss_adv, labels.view(-1, 1) != -1).mean()\n",
    "            # 反向传播，并在正常的grad基础上，累加对抗训练的梯度\n",
    "            loss_adv.backward() \n",
    "            # 恢复embedding参数\n",
    "            fgm.restore() \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "            if CFG.batch_scheduler:\n",
    "                scheduler.step()\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'LR: {lr:.8f}  '\n",
    "                  .format(epoch+1, step, len(train_loader), \n",
    "                          remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                          loss=losses,\n",
    "                          lr=scheduler.get_lr()[0]))\n",
    "        \n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    losses = AverageMeter()\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    for step, (inputs, labels) in enumerate(valid_loader):\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n",
    "        loss = torch.masked_select(loss, labels.view(-1, 1) != -1).mean()\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        preds.append(y_preds.sigmoid().to('cpu').numpy())\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  .format(step, len(valid_loader),\n",
    "                          loss=losses,\n",
    "                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions\n",
    "\n",
    "\n",
    "def inference_fn(test_loader, model, device):\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    tk0 = tqdm(test_loader, total=len(test_loader))\n",
    "    for inputs in tk0:\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "        preds.append(y_preds.sigmoid().to('cpu').numpy())\n",
    "    predictions = np.concatenate(preds)\n",
    "    return predictions\n",
    "\n",
    "# ====================================================\n",
    "# train loop\n",
    "# ====================================================\n",
    "def train_loop(folds, fold):\n",
    "    \n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # loader\n",
    "    # ====================================================\n",
    "    train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n",
    "    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n",
    "    valid_texts = valid_folds['pn_history'].values\n",
    "    valid_labels = create_labels_for_scoring(valid_folds)\n",
    "    \n",
    "    train_dataset = TrainDataset(CFG, train_folds)\n",
    "    valid_dataset = TrainDataset(CFG, valid_folds)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=CFG.batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset,\n",
    "                              batch_size=CFG.batch_size,\n",
    "                              shuffle=False,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "    # calculate warm up steps\n",
    "    CFG.num_warmup_steps = int(CFG.num_warmup_steps * len(train_dataset) / CFG.batch_size * CFG.epochs)\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    model = CustomModel(CFG, config_path=None, pretrained=True)\n",
    "    torch.save(model.config, OUTPUT_DIR+'config.pth')\n",
    "    model.to(device)\n",
    "    \n",
    "    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n",
    "        param_optimizer = list(model.named_parameters())\n",
    "        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_parameters = [\n",
    "            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "             'lr': encoder_lr, 'weight_decay': weight_decay},\n",
    "            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "             'lr': encoder_lr, 'weight_decay': 0.0},\n",
    "            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n",
    "             'lr': decoder_lr, 'weight_decay': 0.0}\n",
    "        ]\n",
    "        return optimizer_parameters\n",
    "\n",
    "    optimizer_parameters = get_optimizer_params(model,\n",
    "                                                encoder_lr=CFG.encoder_lr, \n",
    "                                                decoder_lr=CFG.decoder_lr,\n",
    "                                                weight_decay=CFG.weight_decay)\n",
    "    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n",
    "    \n",
    "    # ====================================================\n",
    "    # scheduler\n",
    "    # ====================================================\n",
    "    def get_scheduler(cfg, optimizer, num_train_steps):\n",
    "        if cfg.scheduler=='linear':\n",
    "            scheduler = get_linear_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n",
    "            )\n",
    "        elif cfg.scheduler=='cosine':\n",
    "            scheduler = get_cosine_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n",
    "            )\n",
    "        return scheduler\n",
    "    \n",
    "    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n",
    "    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "    \n",
    "    best_score = 0.\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "\n",
    "        # eval\n",
    "        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n",
    "        predictions = predictions.reshape((len(valid_folds), CFG.max_len))\n",
    "        \n",
    "        # scoring\n",
    "        char_probs = get_char_probs(valid_texts, predictions, CFG.tokenizer)\n",
    "        results = get_results(char_probs, th=0.5)\n",
    "        preds = get_predictions(results)\n",
    "        score = get_score(valid_labels, preds)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n",
    "        \n",
    "        \n",
    "        if best_score < score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "            torch.save({'model': model.state_dict(),\n",
    "                        'predictions': predictions},\n",
    "                        OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n",
    "\n",
    "    predictions = torch.load(OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n",
    "                             map_location=torch.device('cpu'))['predictions']\n",
    "    valid_folds[[i for i in range(CFG.max_len)]] = predictions\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    del scheduler\n",
    "    del optimizer\n",
    "    del model\n",
    "    return valid_folds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-24T08:52:30.138556Z",
     "iopub.status.busy": "2022-02-24T08:52:30.137189Z",
     "iopub.status.idle": "2022-02-24T08:52:36.954535Z",
     "shell.execute_reply": "2022-02-24T08:52:36.953196Z",
     "shell.execute_reply.started": "2022-02-24T08:52:30.138457Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    def get_result(oof_df):\n",
    "        labels = create_labels_for_scoring(oof_df)\n",
    "        predictions = oof_df[[i for i in range(CFG.max_len)]].values\n",
    "        char_probs = get_char_probs(oof_df['pn_history'].values, predictions, CFG.tokenizer)\n",
    "        results = get_results(char_probs, th=0.5)\n",
    "        preds = get_predictions(results)\n",
    "        score = get_score(labels, preds)\n",
    "        LOGGER.info(f'Score: {score:<.4f}')\n",
    "    \n",
    "    if CFG.train:\n",
    "        oof_df = pd.DataFrame()\n",
    "        for fold in range(CFG.n_fold):\n",
    "            if fold in CFG.trn_fold:\n",
    "                _oof_df = train_loop(train, fold)\n",
    "                oof_df = pd.concat([oof_df, _oof_df])\n",
    "                LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "                get_result(_oof_df)\n",
    "                _oof_df.to_pickle(OUTPUT_DIR+'oof_df_{}.pkl'.format(fold))\n",
    "        oof_df = oof_df.reset_index(drop=True)\n",
    "        LOGGER.info(f\"========== CV ==========\")\n",
    "        get_result(oof_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
